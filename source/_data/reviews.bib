@thesis{balasubramanianDiscoveryImplementationFast2019,
    author = {Balasubramanian, Adarsh},
    date = {2019},
    institution = {{Johns Hopkins University}},
    title = {Discovery and {{Implementation}} of Fast, Accurate and Transferable {{Many}}-Body {{Interatomic Potentials}}},
    type = {PhD Thesis}
}

@article{behlerFourGenerationsHighdimensional2021,
    abstract = {Since their introduction about 25 years ago, machine learning (ML) potentials have become an important tool in the field of atomistic simulations. After the initial decade, in which neural networks were successfully used to construct potentials for rather small molecular systems, the development of high-dimensional neural network potentials (HDNNPs) in 2007 opened the way for the application of ML potentials in simulations of large systems containing thousands of atoms. To date, many other types of ML potentials have been proposed continuously increasing the range of problems that can be studied. In this review, the methodology of the family of HDNNPs including new recent developments will be discussed using a classification scheme into four generations of potentials, which is also applicable to many other types of ML potentials. The first generation is formed by early neural network potentials designed for low-dimensional systems. High-dimensional neural network potentials established the second generation and are based on three key steps: first, the expression of the total energy as a sum of environment-dependent atomic energy contributions; second, the description of the atomic environments by atom-centered symmetry functions as descriptors fulfilling the requirements of rotational, translational, and permutation invariance; and third, the iterative construction of the reference electronic structure data sets by active learning. In third-generation HDNNPs, in addition, long-range interactions are included employing environment-dependent partial charges expressed by atomic neural networks. In fourth-generation HDNNPs, which are just emerging, in addition, nonlocal phenomena such as long-range charge transfer can be included. The applicability and remaining limitations of HDNNPs are discussed along with an outlook at possible future developments.},
    author = {Behler, Jörg},
    date = {2021},
    doi = {10.1021/acs.chemrev.0c00868},
    journaltitle = {Chemical Reviews},
    publisher = {{American Chemical Society}},
    title = {Four Generations of High-Dimensional Neural Network Potentials},
    url = {https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.0c00868}
}

@thesis{carboneDynamicalProcessesCondensed2021,
    abstract = {In this thesis, we study a broad range of physical phenomena from the perspectives of theorydriven, and machine learning models. We begin by introducing a generalization of the Momentum Average method for finding numerically exact Green’s functions of arbitrary polaron systems at zero and finite temperature. This method utilizes the physical ansatz that phonons are produced largely in clouds, and systematically constructs a closure of auxiliary Green’s functions to ultimately solve for the spectrum. We seamlessly apply this method to a variety of problems, including the Holstein, Peierls, and mixed-boson mode models. Next, we leverage fundamental quantum mechanics to develop a microscopic model of exciton and trion scattering in monolayer transition metal dichalcogenides. We conclude that elastic scattering mechanisms are largely the dominant contributor, and confirm that our calculated doping-dependent linewidths qualitatively agree with experiment. In addition, we use Monte Carlo dynamics to examine entropically activated dynamics in continuous phase space models, and show that global and local dynamics both exhibit entropy-driven activation. The second type of work discussed in this thesis pertains to data-driven machine learning models. These approaches offer the utility of instantaneous inference, which has tremendous potential application in applied science in areas such as surrogate modeling and creating digital twins of expensive experiments. First, we demonstrate that x-ray absorption spectra can be used to classify absorbing sites’ local atomic information, specifically its coordination number. Next, we show that graph-based neural networks can to quantitative accuracy, predict the x-ray absorption spectrum of small molecules in the QM9 database. We highlight the various ways in which these types of methodologies can be applied to e.g. closing the design loop and surrogate modeling in general.},
    author = {Carbone, Matthew Ralph},
    date = {2021},
    institution = {{Columbia University}},
    shorttitle = {Dynamical Processes in the Condensed Phase},
    title = {Dynamical Processes in the Condensed Phase: Methods and Models},
    type = {PhD Thesis}
}

@article{carleoMachineLearningPhysical2019,
    abstract = {Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges.},
    annotation = {WOS:000505697300001},
    author = {Carleo, Giuseppe and Cirac, Ignacio and Cranmer, Kyle and Daudet, Laurent and Schuld, Maria and Tishby, Naftali and Vogt-Maranto, Leslie and Zdeborova, Lenka},
    date = {2019-12-06},
    doi = {10.1103/RevModPhys.91.045002},
    issn = {0034-6861},
    journaltitle = {Reviews of Modern Physics},
    langid = {english},
    location = {{College Pk}},
    number = {4},
    pages = {045002},
    publisher = {{Amer Physical Soc}},
    shortjournal = {Rev. Mod. Phys.},
    title = {Machine Learning and the Physical Sciences},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/5},
    urldate = {2021-08-06},
    volume = {91}
}

@article{coleyAutonomousDiscoveryChemical2020a,
    abstract = {This two-part Review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this first part, we describe a classification for discoveries of physical matter (molecules, materials, devices), processes, and models and how they are unified as search problems. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy. Finally, we describe many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science. These illustrate how rapid advancements in hardware automation and machine learning continue to transform the nature of experimentation and modeling. Part two reflects on these case studies and identifies a set of open challenges for the field.},
    annotation = {WOS:000538529000001},
    author = {Coley, Connor W. and Eyke, Natalie S. and Jensen, Klavs F.},
    date = {2020-12-14},
    doi = {10.1002/anie.201909987},
    issn = {1433-7851},
    journaltitle = {Angewandte Chemie-International Edition},
    langid = {english},
    location = {{Weinheim}},
    number = {51},
    pages = {22858--22893},
    publisher = {{Wiley-V C H Verlag Gmbh}},
    shortjournal = {Angew. Chem.-Int. Edit.},
    shorttitle = {Autonomous {{Discovery}} in the {{Chemical Sciences Part I}}},
    title = {Autonomous {{Discovery}} in the {{Chemical Sciences Part I}}: {{Progress}}},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/4},
    urldate = {2021-08-06},
    volume = {59}
}

@thesis{costamagnaDesigningModelsUsing2020,
    author = {Costamagna, Andrea},
    date = {2020},
    institution = {{Politecnico di Torino}},
    shorttitle = {Designing Models Using Machine Learning},
    title = {Designing Models Using Machine Learning: One-Body Reduced Density Matrices and Spectra},
    type = {PhD Thesis}
}

@thesis{doyleInterfacialPotentialsIon2020,
    author = {Doyle, Carrie Conor},
    date = {2020},
    institution = {{University of Cincinnati}},
    title = {Interfacial {{Potentials}} in {{Ion Solvation}}},
    type = {PhD Thesis}
}

@article{dralMolecularExcitedStates2021,
    abstract = {Theoretical simulations of electronic excitations and associated processes in molecules are indispensable for fundamental research and technological innovations. However, such simulations are notoriously challenging to perform with quantum mechanical methods. Advances in machine learning open many new avenues for assisting molecular excited-state simulations. In this Review, we track such progress, assess the current state of the art and highlight the critical issues to solve in the future. We overview a broad range of machine learning applications in excited-state research, which include the prediction of molecular properties, improvements of quantum mechanical methods for the calculations of excited-state properties and the search for new materials. Machine learning approaches can help us understand hidden factors that influence photo-processes, leading to a better control of such processes and new rules for the design of materials for optoelectronic applications.},
    annotation = {WOS:000652426900001},
    author = {Dral, Pavlo O. and Barbatti, Mario},
    date = {2021-06},
    doi = {10.1038/s41570-021-00278-1},
    journaltitle = {Nature Reviews Chemistry},
    langid = {english},
    location = {{Berlin}},
    number = {6},
    pages = {388--405},
    publisher = {{Nature Research}},
    shortjournal = {Nat. Rev. Chem.},
    title = {Molecular Excited States through a Machine Learning Lens},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06},
    volume = {5}
}

@incollection{fischerCharacterizingMagneticSkyrmions2021,
    author = {Fischer, Peter and Roy, Sujoy},
    booktitle = {Magnetic {{Skyrmions}} and {{Their Applications}}},
    date = {2021},
    pages = {55--97},
    publisher = {{Elsevier}},
    title = {Characterizing Magnetic Skyrmions at Their Fundamental Length and Time Scales}
}

@article{glielmoUnsupervisedLearningMethods2021,
    abstract = {Unsupervised learning is becoming an essential tool to analyze the increasingly large amounts of data produced by atomistic and molecular simulations, in material science, solid state physics, biophysics, and biochemistry. In this Review, we provide a comprehensive overview of the methods of unsupervised learning that have been most commonly used to investigate simulation data and indicate likely directions for further developments in the field. In particular, we discuss feature representation of molecular systems and present state-of-the-art algorithms of dimensionality reduction, density estimation, and clustering, and kinetic models. We divide our discussion into self-contained sections, each discussing a specific method. In each section, we briefly touch upon the mathematical and algorithmic foundations of the method, highlight its strengths and limitations, and describe the specific ways in which it has been used-or can be used-to analyze molecular simulation data.},
    author = {Glielmo, Aldo and Husic, Brooke E. and Rodriguez, Alex and Clementi, Cecilia and Noé, Frank and Laio, Alessandro},
    date = {2021},
    doi = {10.1021/acs.chemrev.0c01195},
    journaltitle = {Chemical Reviews},
    publisher = {{ACS Publications}},
    title = {Unsupervised {{Learning Methods}} for {{Molecular Simulation Data}}},
    url = {https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.0c01195}
}

@article{goncalvesmarquesStructureDynamicsMaterials2020,
    author = {Gonçalves Marques, Mário Rui},
    date = {2020},
    title = {The Structure and Dynamics of Materials Using Machine Learning}
}

@article{greenstreetMachinelearningassistedModeling2021,
    abstract = {By integrating artificial intelligence algorithms and physics-based simulations, researchers are developing new models that are both reliable and interpretable.},
    annotation = {WOS:000668845000013},
    author = {Greenstreet, Sarah},
    date = {2021-07-01},
    doi = {10.1063/PT.3.4794},
    issn = {0031-9228},
    journaltitle = {Physics Today},
    langid = {english},
    location = {{Melville}},
    number = {7},
    pages = {42--47},
    publisher = {{Amer Inst Physics}},
    shortjournal = {Phys. Today},
    title = {Machine-Learning-Assisted Modeling},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06},
    volume = {74}
}

@incollection{grisafiAtomicscaleRepresentationStatistical2019,
    author = {Grisafi, Andrea and Wilkins, David M. and Willatt, Michael J. and Ceriotti, Michele},
    booktitle = {Machine {{Learning}} in {{Chemistry}}: {{Data}}-{{Driven Algorithms}}, {{Learning Systems}}, and {{Predictions}}},
    date = {2019},
    pages = {1--21},
    publisher = {{ACS Publications}},
    title = {Atomic-Scale Representation and Statistical Learning of Tensorial Properties}
}

@article{guAdaptiveIronbasedMagnetic2021,
    abstract = {With unique physicochemical properties and biological effects, magnetic nanomaterials (MNMs) play a crucial role in the biomedical field. In particular, magnetic iron oxide nanoparticles (MIONPs) are approved by the United States Food and Drug Administration (FDA) for clinical applications at present due to their low toxicity, biocompatibility, and biodegradability. Despite the unarguable effectiveness, massive space for improving such materials' performance still needs to be filled. Recently, many efforts have been devoted to improving the preparation methods based on the materials' biosafety. Besides, researchers have successfully regulated the performance of magnetic nanoparticles (MNPs) by changing their sizes, morphologies, compositions; or by aggregating as-synthesized MNPs in an orderly arrangement to meet various clinical requirements. The rise of cloud computing and artificial intelligence techniques provides novel ways for fast material characterization, automated data analysis, and mechanism demonstration. In this review, we summarized the studies that focused on the preparation routes and performance regulations of high-quality MNPs, and their special properties applied in biomedical detection, diagnosis, and treatment. At the same time, the future development of MNMs was also discussed.},
    annotation = {WOS:000663236300002},
    author = {Gu, Ning and Zhang, Zuoheng and Li, Yan},
    date = {2021},
    doi = {10.1007/s12274-021-3546-1},
    issn = {1998-0124},
    journaltitle = {Nano Research},
    langid = {english},
    location = {{Beijing}},
    publisher = {{Tsinghua Univ Press}},
    shortjournal = {Nano Res.},
    title = {Adaptive Iron-Based Magnetic Nanomaterials of High Performance for Biomedical Applications},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06}
}

@thesis{hanDeepLearningLargescale2018,
    author = {Han, Jiequn},
    date = {2018},
    institution = {{Princeton University}},
    title = {Deep {{Learning}} for {{Large}}-Scale {{Molecular Dynamics}} and {{High}}-Dimensional {{Partial Differential Equations}}},
    type = {PhD Thesis}
}

@article{hartMachineLearningAlloys2021,
    abstract = {Alloy modelling has a history of machine-learning-like approaches, preceding the tide of data-science-inspired work. The dawn of computational databases has made the integration of analysis, prediction and discovery the key theme in accelerated alloy research. Advances in machine-learning methods and enhanced data generation have created a fertile ground for computational materials science. Pairing machine learning and alloys has proven to be particularly instrumental in pushing progress in a wide variety of materials, including metallic glasses, high-entropy alloys, shape-memory alloys, magnets, superalloys, catalysts and structural materials. This Review examines the present state of machine-learning-driven alloy research, discusses the approaches and applications in the field and summarizes theoretical predictions and experimental validations. We foresee that the partnership between machine learning and alloys will lead to the design of new and improved systems. Machine learning is enabling a metallurgical renaissance. This Review discusses recent progress in representations, descriptors and interatomic potentials, overviewing metallic glasses, high-entropy alloys, superalloys and shape-memory alloys, magnets and catalysts, and the prediction of mechanical and thermal properties.},
    annotation = {WOS:000675035000001},
    author = {Hart, Gus L. W. and Mueller, Tim and Toher, Cormac and Curtarolo, Stefano},
    date = {2021},
    doi = {10.1038/s41578-021-00340-w},
    issn = {2058-8437},
    journaltitle = {Nature Reviews Materials},
    langid = {english},
    location = {{Berlin}},
    publisher = {{Nature Research}},
    shortjournal = {Nat. Rev. Mater.},
    title = {Machine Learning for Alloys},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06}
}

@incollection{heryadiCharacterizingPerformanceImprovement2019,
    author = {Heryadi, Dodi and Hampton, Scott},
    booktitle = {Proceedings of the {{Practice}} and {{Experience}} in {{Advanced Research Computing}} on {{Rise}} of the {{Machines}} (Learning)},
    date = {2019},
    pages = {1--5},
    title = {Characterizing {{Performance Improvement}} of {{GPUs}}}
}

@article{karniadakisPhysicsinformedMachineLearning2021,
    abstract = {The rapidly developing field of physics-informed learning integrates data and mathematical models seamlessly, enabling accurate inference of realistic and high-dimensional multiphysics problems. This Review discusses the methodology and provides diverse examples and an outlook for further developments. Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.},
    annotation = {WOS:000653612800001},
    author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
    date = {2021-06},
    doi = {10.1038/s42254-021-00314-5},
    journaltitle = {Nature Reviews Physics},
    langid = {english},
    location = {{London}},
    number = {6},
    pages = {422--440},
    publisher = {{Springernature}},
    shortjournal = {Nat. Rev. Phys.},
    title = {Physics-Informed Machine Learning},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06},
    volume = {3}
}

@article{Kocer2021,
    abstract = {In the past two decades, machine learning potentials (MLP) have reached a level of maturity that now enables applications to large-scale atomistic simulations of a wide range of systems in chemistry, physics and materials science. Different machine learning algorithms have been used with great success in the construction of these MLPs. In this review, we discuss an important group of MLPs relying on artificial neural networks to establish a mapping from the atomic structure to the potential energy. In spite of this common feature, there are important conceptual differences, which concern the dimensionality of the systems, the inclusion of long-range electrostatic interactions, global phenomena like non-local charge transfer, and the type of descriptor used to represent the atomic structure, which can either be predefined or learnable. A concise overview is given along with a discussion of the open challenges in the field.},
    author = {Kocer, Emir and Ko, TW Tsz Wai and Behler, Jörg and Behler, J},
    date = {2021-07},
    journaltitle = {arxiv.org},
    title = {Neural Network Potentials: {{A}} Concise Overview of Methods},
    url = {https://arxiv.org/abs/2107.03727 http://arxiv.org/abs/2107.03727}
}

@thesis{koFirstPrinciplesStudyStructural2019,
    author = {Ko, Hsin-Yu},
    date = {2019},
    institution = {{Princeton University}},
    title = {First-{{Principles Study}} on the {{Structural}} and {{Thermal Properties}} of {{Molecular Crystals}} and {{Liquids}}},
    type = {PhD Thesis}
}

@incollection{komeijiFMOInterfacedMolecular2021,
    abstract = {Three ways to combine FMO and MD are described: FMO-MD, FMO-QM/MM-MD, and MM-MD/FMO. FMO-MD is an ab initio MD in which force is updated on-the-fly by FMO. FMO-QM/MM-MD is a QM/MM-MD method in which the QM part is calculated by FMO. MM-MD/FMO is a simulation protocol in which FMO calculation is performed for molecular configurations generated by MM-MD. The methodology and application of these methods are described and compared.},
    author = {Komeiji, Yuto and Ishikawa, Takeshi},
    booktitle = {Recent {{Advances}} of the {{Fragment Molecular Orbital Method}}},
    date = {2021},
    pages = {373--389},
    publisher = {{Springer}},
    title = {{{FMO Interfaced}} with {{Molecular Dynamics Simulation}}},
    url = {https://link.springer.com/chapter/10.1007/978-981-15-9235-5_19}
}

@thesis{lefdalsnesClassicalMolecularDynamics2019,
    author = {Lefdalsnes, Andreas Godø},
    date = {2019},
    title = {Classical {{Molecular Dynamics}} Using {{Neural Network Representations}} of {{Potential Energy Surfaces}}},
    type = {Master's Thesis}
}

@article{leModelingElectrifiedMetal2021,
    abstract = {The structure and potential distribution of electric double layers (EDLs) are of close relevance to the performance of electrode materials. In the past years, despite tremendous efforts devoted to this topic, an atomistic picture of the EDL is still lacking, let alone understanding on how the EDL structure is related to the dielectric property of interface water. In this article, we briefly review the recent progress in modeling electrified metal/water interfaces using ab initio molecular dynamics (AIMD). The ab initio methods for EDL modeling is firstly summarized, and then we discuss the structures of interface water on metal electrodes at different potential conditions. Moreover, we illustrate the potential-dependent behavior of chemisorbed water on Pt(111) surface and its relationship with the peak of the differential Helmholtz capacitance observed by experiment. At last, we give some perspective for future development in ab initio modeling of electrochemical interfaces.},
    author = {Le, Jia-Bo and Cheng, Jun},
    date = {2021-06},
    doi = {10/ghtqnk},
    issn = {24519103},
    journaltitle = {Current Opinion in Electrochemistry},
    langid = {english},
    pages = {100693},
    shortjournal = {Current Opinion in Electrochemistry},
    shorttitle = {Modeling Electrified Metal/Water Interfaces from Ab Initio Molecular Dynamics},
    title = {Modeling Electrified Metal/Water Interfaces from Ab Initio Molecular Dynamics: {{Structure}} and {{Helmholtz}} Capacitance},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S2451910321000077},
    urldate = {2021-08-11},
    volume = {27}
}

@thesis{liMolecularDynamicsStudy2021,
    abstract = {Although electrostatics interactions in  uids have been studied for many decades, new results in this field are still challenging our classical understanding of electrolytes. The combination of electrostatics and self-assembly yields many interesting yet challenging problems that are of fundamental scienti
c interest and show promise for industrial applications. In this dissertation, I introduce our work on the topic of charged nanomaterials in aqueous salt solutions and how electrostatics play a role in different systems. The work summarized here is an attempt to develop methods to correctly model nanoscale charged systems in both low and high salt environments, and tackle the problem of simulating large systems with MD simulations by using coarse-graining techniques. First, we study nanoparticles immersed in concentrated monovalent salt ({$>$}0.5 mol/L1) using multi-scale molecular dynamics (MD) simulations involving atomic resolution and coarse-grained representations with implicit solvent. We attaind a surprising attractive to repulsive and then attractive re-entrant behavior as a function of salt concentration that cannot be predicted by previous theories and propose a rational explanation. Next, we explore the interaction of cylindrical interfaces in NaCl solutions to 
nd the screening length of charged cylinders and compare them with the prediction of the Poisson-Boltzmann (PB) equation. We also 
nd a depletion attraction between cylinders at high monovalent salt concentrations. We compare the results of MD simulations to mean-field theories as well as liquid state theory that incorporates ion correlations, and we show that the short-range ion correlations significantly impact the interactions between cylinders in concentrated monovalent salt solutions. Finally, we look into the complex biological system of bacterial microcompartment (MCP) assembly. Using all-atom (AA, explicit water, and ion) and coarse-grained (CG, implicit ion) MD simulations, combined with thermodynamics analysis, we find that electrostatic interactions (hydrogen bonds and charge distributions) play an important role in the self-assembly of native propanediol utilization (Pdu) MCPs. Combining AA and CG MD simulations, we predict various polyhedral and extended assembly shapes, and we predict what kinds of mutations lead to the success or failure of MCP assembly. The simulation and theoretical predictions match with the experimental observation of our collaborators and with published experiments.},
    author = {Li, Yaohua},
    date = {2021},
    institution = {{Northwestern University}},
    shorttitle = {Molecular {{Dynamics Study}} of {{Charged Nanomaterials}}},
    title = {Molecular {{Dynamics Study}} of {{Charged Nanomaterials}}: {{Electrostatics}} and {{Self}}-{{Assembly}}},
    type = {PhD Thesis}
}

@article{louieDiscoveringUnderstandingMaterials2021,
    abstract = {Materials modelling and design using computational quantum and classical approaches is by now well established as an essential pillar in condensed matter physics, chemistry and materials science research, in addition to experiments and analytical theories. The past few decades have witnessed tremendous advances in methodology development and applications to understand and predict the ground-state, excited-state and dynamical properties of materials, ranging from molecules to nanoscopic/mesoscopic materials to bulk and reduced-dimensional systems. This issue of Nature Materials presents four in-depth Review Articles on the field. This Perspective aims to give a brief overview of the progress, as well as provide some comments on future challenges and opportunities. We envision that increasingly powerful and versatile computational approaches, coupled with new conceptual understandings and the growth of techniques such as machine learning, will play a guiding role in the future search and discovery of materials for science and technology. This Perspective provides an overview of the different approaches used to understand the behaviour of materials at different length scales and timescales through computation, and outlines future challenges in the description of complex systems or ultrafast non-equilibrium behaviour.},
    annotation = {WOS:000655912800009},
    author = {Louie, Steven G. and Chan, Yang-Hao and da Jornada, Felipe H. and Li, Zhenglu and Qiu, Diana Y.},
    date = {2021-06},
    doi = {10.1038/s41563-021-01015-1},
    issn = {1476-1122},
    journaltitle = {Nature Materials},
    langid = {english},
    location = {{Berlin}},
    number = {6},
    options = {useprefix=true},
    pages = {728--735},
    publisher = {{Nature Research}},
    shortjournal = {Nat. Mater.},
    title = {Discovering and Understanding Materials through Computation},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06},
    volume = {20}
}

@article{luFutureDirectionsChemical2021,
    author = {Lu, Yuyuan and Deng, Geng and Shuai, Zhigang},
    date = {2021},
    doi = {10.1515/pac-2020-1006},
    journaltitle = {Pure and Applied Chemistry},
    publisher = {{De Gruyter}},
    title = {Future Directions of Chemical Theory and Computation}
}

@thesis{luIntegratingMachineLearning2020,
    author = {Lu, Jianing},
    date = {2020},
    institution = {{New York University}},
    title = {Integrating {{Machine Learning}} into {{Protein}}-{{Ligand Scoring Function Development}}},
    type = {PhD Thesis}
}

@article{martinaDevelopmentMachineLearning,
    abstract = {Recent experimental research showed that nucleotides, under favorable conditions of temperature and concentration, can self-assemble into liquid crystals. The mechanism involves the stacking of nucleotides into columnar aggregates. It has been proposed that this ordered structure can favor the polymerization of long nucleotide chains, which is a fundamental step toward the so called “RNA world”. In this thesis, starting from ab initio molecular dynamics simulations, at the density functional theory level, an all-atom potential for nucleotides in water, based on an implicit neural network representation, has been developed. Its stability and accuracy have been tested and its predictions on simple model systems have been compared with data generated both ab initio and using currently available empirical force field for nucleic acids.},
    author = {Martina, Riccardo},
    langid = {english},
    pages = {57},
    title = {Development of a Machine Learning Potential for Nucleotides in Water}
}

@article{meuwlyMachineLearningChemical2021,
    abstract = {Machine learning (ML) techniques applied to chemical reactions have a long history. The present contribution discusses applications ranging from small molecule reaction dynamics to computational platforms for reaction planning. ML-based techniques can be particularly relevant for problems involving both computation and experiments. For one, Bayesian inference is a powerful approach to develop models consistent with knowledge from experiments. Second, ML-based methods can also be used to handle problems that are formally intractable using conventional approaches, such as exhaustive characterization of state-to-state information in reactive collisions. Finally, the explicit simulation of reactive networks as they occur in combustion has become possible using machine-learned neural network potentials. This review provides an overview of the questions that can and have been addressed using machine learning techniques, and an outlook discusses challenges in this diverse and stimulating field. It is concluded that ML applied to chemistry problems as practiced and conceived today has the potential to transform the way with which the field approaches problems involving chemical reactions, in both research and academic teaching.},
    author = {Meuwly, Markus},
    date = {2021},
    doi = {10.1021/acs.chemrev.1c00033},
    journaltitle = {Chemical Reviews},
    publisher = {{ACS Publications}},
    title = {Machine {{Learning}} for {{Chemical Reactions}}},
    url = {https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.1c00033}
}

@article{mikschStrategiesConstructionMachinelearning2021,
    abstract = {Recent advances in machine-learning interatomic potentials have enabled the efficient modeling of complex atomistic systems with an accuracy that is comparable to that of conventional quantum-mechanics based methods. At the same time, the construction of new machine-learning potentials can seem a daunting task, as it involves data-science techniques that are not yet common in chemistry and materials science. Here, we provide a tutorial-style overview of strategies and best practices for the construction of artificial neural network (ANN) potentials. We illustrate the most important aspects of (a) data collection, (b) model selection, (c) training and validation, and (d) testing and refinement of ANN potentials on the basis of practical examples. Current research in the areas of active learning and delta learning are also discussed in the context of ANN potentials. This tutorial review aims at equipping computational chemists and materials scientists with the required background knowledge for ANN potential construction and application, with the intention to accelerate the adoption of the method, so that it can facilitate exciting research that would otherwise be challenging with conventional strategies.},
    annotation = {WOS:000674925500001},
    author = {Miksch, April M. and Morawietz, Tobias and Kaestner, Johannes and Urban, Alexander and Artrith, Nongnuch},
    date = {2021-09},
    doi = {10.1088/2632-2153/abfd96},
    journaltitle = {Machine Learning-Science and Technology},
    langid = {english},
    location = {{Bristol}},
    number = {3},
    pages = {031001},
    publisher = {{Iop Publishing Ltd}},
    shortjournal = {Mach. Learn.-Sci. Technol.},
    title = {Strategies for the Construction of Machine-Learning Potentials for Accurate and Efficient Atomic-Scale Simulations},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06},
    volume = {2}
}

@article{moqadamMembraneModelsMolecular2021,
    abstract = {Peripheral membrane proteins (PMPs) bind temporarily to the surface of biological membranes. They also exist in a soluble form and their tertiary structure is often known. Yet, their membrane-bound form and their interfacial-binding site with membrane lipids remain difficult to observe directly. Their binding and unbinding mechanism, the conformational changes of the PMPs and their influence on the membrane structure are notoriously challenging to study experimentally. Molecular dynamics simulations are particularly useful to fill some knowledge-gaps and provide hypothesis that can be experimentally challenged to further our understanding of PMP-membrane recognition. Because of the time-scales of PMP-membrane binding events and the computational costs associated with molecular dynamics simulations, membrane models at different levels of resolution are used and often combined in multiscale simulation strategies. We here review membrane models belonging to three classes: atomistic, coarse-grained and implicit. Differences between models are rooted in the underlying theories and the reference data they are parameterized against. The choice of membrane model should therefore not only be guided by its computational efficiency. The range of applications of each model is discussed and illustrated using examples from the literature. [GRAPHICS] .},
    annotation = {WOS:000669104100001},
    author = {Moqadam, Mahmoud and Tubiana, Thibault and Moutoussamy, Emmanuel E. and Reuter, Nathalie},
    date = {2021-01-01},
    doi = {10.1080/23746149.2021.1932589},
    issn = {2374-6149},
    journaltitle = {Advances in Physics-X},
    langid = {english},
    location = {{Abingdon}},
    number = {1},
    pages = {1932589},
    publisher = {{Taylor \& Francis Ltd}},
    shortjournal = {Adv. Phys.-X},
    title = {Membrane Models for Molecular Simulations of Peripheral Membrane Proteins},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/2},
    urldate = {2021-08-06},
    volume = {6}
}

@article{morawietzMachineLearningacceleratedQuantum2021,
    abstract = {Atomistic simulations have become an invaluable tool for industrial applications ranging from the optimization of protein-ligand interactions for drug discovery to the design of new materials for energy applications. Here we review recent advances in the use of machine learning (ML) methods for accelerated simulations based on a quantum mechanical (QM) description of the system. We show how recent progress in ML methods has dramatically extended the applicability range of conventional QM-based simulations, allowing to calculate industrially relevant properties with enhanced accuracy, at reduced computational cost, and for length and time scales that would have otherwise not been accessible. We illustrate the benefits of ML-accelerated atomistic simulations for industrial R\&D processes by showcasing relevant applications from two very different areas, drug discovery (pharmaceuticals) and energy materials. Writing from the perspective of both a molecular and a materials modeling scientist, this review aims to provide a unified picture of the impact of ML-accelerated atomistic simulations on the pharmaceutical, chemical, and materials industries and gives an outlook on the exciting opportunities that could emerge in the future.},
    annotation = {WOS:000577932000001},
    author = {Morawietz, Tobias and Artrith, Nongnuch},
    date = {2021-04},
    doi = {10.1007/s10822-020-00346-6},
    issn = {0920-654X},
    journaltitle = {Journal of Computer-Aided Molecular Design},
    langid = {english},
    location = {{Dordrecht}},
    number = {4},
    pages = {557--586},
    publisher = {{Springer}},
    shortjournal = {J. Comput.-Aided Mol. Des.},
    title = {Machine Learning-Accelerated Quantum Mechanics-Based Atomistic Simulations for Industrial Applications},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/3},
    urldate = {2021-08-06},
    volume = {35}
}

@article{musilPhysicsinspiredStructuralRepresentations2021,
    abstract = {The first step in the construction of a regression model or a data-driven analysis, aiming to predict or elucidate the relationship between the atomic-scale structure of matter and its properties, involves transforming the Cartesian coordinates of the atoms into a suitable representation. The development of atomic-scale representations has played, and continues to play, a central role in the success of machine-learning methods for chemistry and materials science. This review summarizes the current understanding of the nature and characteristics of the most commonly used structural and chemical descriptions of atomistic structures, highlighting the deep underlying connections between different frameworks and the ideas that lead to computationally efficient and universally applicable models. It emphasizes the link between properties, structures, their physical chemistry, and their mathematical description, provides examples of recent applications to a diverse set of chemical and materials science problems, and outlines the open questions and the most promising research directions in the field.},
    author = {Musil, Felix and Grisafi, Andrea and Bartók, Albert P. and Ortner, Christoph and Csányi, Gábor and Ceriotti, Michele},
    date = {2021},
    doi = {10.1021/acs.chemrev.1c00021},
    journaltitle = {Chemical Reviews},
    publisher = {{ACS Publications}},
    title = {Physics-Inspired Structural Representations for Molecules and Materials},
    url = {https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.1c00021}
}

@thesis{pulighedduComputationalPredictionsThermal2020,
    author = {Puligheddu, Marcello},
    date = {2020},
    institution = {{The University of Chicago}},
    title = {Computational {{Predictions}} of the {{Thermal Conductivity}} of {{Solids}} and {{Liquids}}},
    type = {PhD Thesis}
}

@thesis{roccaRANDOMPHASEAPPROXIMATION2020,
    abstract = {Despite the high computational cost the adiabatic connection fluctuation dissipation theorem (ACFDT) represents a promising approach to improve the description of the electronic correlation within density functional theory. The simplest approximation that can be applied in the context of the ACFDT is the random phase approximation (RPA). First, we show how the RPA can be improved by introducing a kernel containing an approximate electron-hole exchange term that leads to two different beyond-RPA methods. Then, we show that the RPA and beyond-RPA approaches can be efficiently computed within a plane-wave basis set implementation by using dielectric eigenpotentials as a compact auxiliary basis set and the Lanczos algorithm. A series of applications to molecules and solids are presented to demonstrate the efficiency and accuracy of these approximations. Importantly, it will be shown that the highly accurate beyond-RPA methods can be scaled to treat molecular systems with one hundred electrons requiring a basis set with hundreds of thousands of plane-waves. Finally, it is shown how the sophisticated and computationally expensive ACFDT methods can be used to compute finite-temperature properties of realistic materials (adsorption enthalpies of molecules in zeolites) by coupling molecular-dynamics simulations with machine learning algorithms.},
    author = {Rocca, Dario},
    date = {2020},
    institution = {{Université de Lorraine}},
    shorttitle = {{{RANDOM PHASE APPROXIMATION AND BEYOND}}},
    title = {{{RANDOM PHASE APPROXIMATION AND BEYOND}}: {{FROM THEORY TO REALISTIC MATERIALS}}},
    type = {PhD Thesis}
}

@article{rousseauTheoreticalInsightsSurface2020,
    abstract = {Redox-active oxides find use in many applications, including catalysts, photovoltaic devices, self-cleaning glasses, chemical sensors and electronic components. Their utility derives from their unique ability to access multiple metal-charge states within a finite energy window. However, this property also confounds our ability to study reducible oxides, because it leads to structural, compositional and electronic complexities that elude simplistic models of materials structure and function. Oxygen vacancies play a critical role in shaping the functional properties of such oxides; most notably, they lead to mobile-charge imbalances that impact surface processes at substantial distances from the originating defect. Atomistic simulations are inherently equipped to illuminate these phenomena at a fundamental level; however, reducible oxides pose great challenges, owing to the high level of electron correlation needed to correctly describe them. Understanding how defects form, couple, propagate, agglomerate or repel each other and influence the surface properties of reducible oxides is only now coming into the grasp of modern theory and simulation capabilities. This knowledge is also key to discovering and controlling emergent materials properties with tunable multifunctionalities at the nanometre scale and beyond. Reducible oxides are tunable, multifunctional materials used in many applications, particularly in catalysis; their attractive properties arise from their interacting charge carriers, complex electronic structure and propensity to form mobile defects. This Review surveys theoretical methods to model and understand reducible oxides, using TiO2 as a prototypical example.},
    annotation = {WOS:000535869400002},
    author = {Rousseau, Roger and Glezakou, Vassiliki-Alexandra and Selloni, Annabella},
    date = {2020-06},
    doi = {10.1038/s41578-020-0198-9},
    issn = {2058-8437},
    journaltitle = {Nature Reviews Materials},
    langid = {english},
    location = {{London}},
    number = {6},
    pages = {460--475},
    publisher = {{Nature Publishing Group}},
    shortjournal = {Nat. Rev. Mater.},
    title = {Theoretical Insights into the Surface Physics and Chemistry of Redox-Active Oxides},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/4},
    urldate = {2021-08-06},
    volume = {5}
}

@incollection{saucedaConstructionMachineLearned2020,
    abstract = {Highly accurate force fields are a mandatory requirement to generate predictive simulations. Here we present the path for the construction of machine learned molecular force fields by discussing the hierarchical pathway from generating the dataset of reference calculations to the construction of the machine learning model, and the validation of the physics generated by the model. We will use the the symmetrized gradient-domain machine learning (sGDML) framework due to its ability to reconstruct complex high-dimensional potential-energy surfaces (PES) with high precision even when using just a few hundreds of molecular conformations for training. The data efficiency of the sGDML model allows using reference atomic forces computed with high-level wavefunction-based approaches, such as the gold standard coupled cluster method with single, double, and perturbative triple excitations (CCSD(T)). We demonstrate that the flexible nature of the sGDML framework captures local and non-local electronic interactions (e.g. H-bonding, lone pairs, steric repulsion, changes in hybridization states (e.g. sp2 sp3), interactions, and proton transfer) without imposing any restriction on the nature of interatomic potentials. The analysis of sGDML models trained for different molecular structures at different levels of theory (e.g. density functional theory and CCSD(T)) provides empirical evidence that a higher level of theory generates a smoother PES. Additionally, a careful analysis of molecular dynamics simulations yields new qualitative insights into dynamics and vibrational spectroscopy of small molecules close to spectroscopic accuracy.},
    author = {Sauceda, Huziel E. and Chmiela, Stefan and Poltavsky, Igor and Müller, Klaus-Robert and Tkatchenko, Alexandre},
    booktitle = {Machine {{Learning Meets Quantum Physics}}},
    date = {2020},
    pages = {277--307},
    publisher = {{Springer}},
    shorttitle = {Construction of Machine Learned Force Fields with Quantum Chemical Accuracy},
    title = {Construction of Machine Learned Force Fields with Quantum Chemical Accuracy: {{Applications}} and Chemical Insights}
}

@article{shaiduInteratomicPotentialLiC2020,
    author = {Shaidu, Yusuf},
    date = {2020},
    publisher = {{SISSA}},
    title = {Interatomic {{Potential}} for {{Li}}-{{C Systems}} from {{Cluster Expansion}} to {{Artificial Neural Network Techniques}}}
}

@article{shaoModellingBulkElectrolytes2021,
    abstract = {Batteries and supercapacitors are electrochemical energy storage systems which involve multiple time-scales and length-scales. In terms of the electrolyte which serves as the ionic conductor, a molecular-level understanding of the corresponding transport phenomena, electrochemical (thermal) stability and interfacial properties is crucial for optimizing the device performance and achieving safety requirements. To this end, atomistic machine learning is a promising technology for bridging microscopic models and macroscopic phenomena. Here, we provide a timely snapshot of recent advances in this area. This includes technical considerations that are particularly relevant for modelling electrolytes as well as specific examples of both bulk electrolytes and associated interfaces. A perspective on methodological challenges and new applications is also discussed.},
    annotation = {WOS:000604327200001},
    author = {Shao, Yunqi and Knijff, Lisanne and Dietrich, Florian M. and Hermansson, Kersti and Zhang, Chao},
    date = {2021-04},
    doi = {10.1002/batt.202000262},
    journaltitle = {Batteries \& Supercaps},
    langid = {english},
    location = {{Weinheim}},
    number = {4},
    pages = {585--595},
    publisher = {{Wiley-V C H Verlag Gmbh}},
    shortjournal = {Batteries Supercaps},
    title = {Modelling {{Bulk Electrolytes}} and {{Electrolyte Interfaces}} with {{Atomistic Machine Learning}}},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/2},
    urldate = {2021-08-06},
    volume = {4}
}

@thesis{srivastavaNeuralNetworkPrediction2020,
    abstract = {The trend of open material data and automation in the past decade offers a unique opportunity for data-driven design of novel materials for various applications as well as fundamental scientific understanding, but it also poses a challenge for conventional machine learning approaches based on structure features. In this thesis, I develop a class of deep learning methods that solve various types of learning problems for solid materials, and demonstrate its application to both accelerate material design and understand scientific knowledge. First, I present a neural network architecture to learn the representations of an arbitrary solid material, which encodes several fundamental symmetries for solid materials as inductive biases. Then, I extend the approach to explore four different learning problems: 1) supervised learning to predict material properties from structures; 2) visualization to understand structure-property relations; 3) unsupervised learning to understand atomic scale dynamics from time series trajectories; 4) active learning to explore an unknown material space. In each learning problem, I demonstrate the performance of the approach compared with previous approaches, and apply it to solve several realistic materials design problems and extract scientific insights from data.},
    author = {Srivastava, Gopal Narayan},
    date = {2020},
    institution = {{The Ohio State University}},
    title = {Neural Network for the Prediction of Force Differences between an Amino Acid in Solution and Vacuum},
    type = {PhD Thesis}
}

@article{unkeMachineLearningForce2021,
    abstract = {In recent years, the use of machine learning (ML) in computational chemistry has enabled numerous advances previously out of reach due to the computational complexity of traditional electronic-structure methods. One of the most promising applications is the construction of ML-based force fields (FFs), with the aim to narrow the gap between the accuracy of ab initio methods and the efficiency of classical FFs. The key idea is to learn the statistical relation between chemical structure and potential energy without relying on a preconceived notion of fixed chemical bonds or knowledge about the relevant interactions. Such universal ML approximations are in principle only limited by the quality and quantity of the reference data used to train them. This review gives an overview of applications of ML-FFs and the chemical insights that can be obtained from them. The core concepts underlying ML-FFs are described in detail, and a step-by-step guide for constructing and testing them from scratch is given. The text concludes with a discussion of the challenges that remain to be overcome by the next generation of ML-FFs.},
    author = {Unke, Oliver T. and Chmiela, Stefan and Sauceda, Huziel E. and Gastegger, Michael and Poltavsky, Igor and Schütt, Kristof T. and Tkatchenko, Alexandre and Müller, Klaus-Robert},
    date = {2021},
    doi = {10.1021/acs.chemrev.0c01111},
    journaltitle = {Chemical Reviews},
    publisher = {{ACS Publications}},
    title = {Machine Learning Force Fields},
    url = {https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.0c01111}
}

@article{vassilev-galindoChallengesMachineLearning2021,
    abstract = {Dynamics of flexible molecules are often determined by an interplay between local chemical bond fluctuations and conformational changes driven by long-range electrostatics and van der Waals interactions. This interplay between interactions yields complex potential-energy surfaces (PESs) with multiple minima and transition paths between them. In this work, we assess the performance of the state-of-the-art Machine Learning (ML) models, namely, sGDML, SchNet, Gaussian Approximation Potentials/Smooth Overlap of Atomic Positions (GAPs/SOAPs), and Behler-Parrinello neural networks, for reproducing such PESs, while using limited amounts of reference data. As a benchmark, we use the cis to trans thermal relaxation in an azobenzene molecule, where at least three different transition mechanisms should be considered. Although GAP/SOAP, SchNet, and sGDML models can globally achieve a chemical accuracy of 1 kcal mol(-1) with fewer than 1000 training points, predictions greatly depend on the ML method used and on the local region of the PES being sampled. Within a given ML method, large differences can be found between predictions of close-to-equilibrium and transition regions, as well as for different transition mechanisms. We identify key challenges that the ML models face mainly due to the intrinsic limitations of commonly used atom-based descriptors. All in all, our results suggest switching from learning the entire PES within a single model to using multiple local models with optimized descriptors, training sets, and architectures for different parts of the complex PES.},
    annotation = {WOS:000630524000019},
    author = {Vassilev-Galindo, Valentin and Fonseca, Gregory and Poltavsky, Igor and Tkatchenko, Alexandre},
    date = {2021-03-07},
    doi = {10.1063/5.0038516},
    issn = {0021-9606},
    journaltitle = {Journal of Chemical Physics},
    langid = {english},
    location = {{Melville}},
    number = {9},
    pages = {094119},
    publisher = {{Amer Inst Physics}},
    shortjournal = {J. Chem. Phys.},
    title = {Challenges for Machine Learning Force Fields in Reproducing Potential Energy Surfaces of Flexible Molecules},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/2},
    urldate = {2021-08-06},
    volume = {154}
}

@incollection{wangForceFieldDevelopment2019,
    author = {Wang, Lee-Ping},
    booktitle = {Computational {{Approaches}} for {{Chemistry Under Extreme Conditions}}},
    date = {2019},
    pages = {127--159},
    publisher = {{Springer}},
    title = {Force {{Field Development}} and {{Nanoreactor Chemistry}}}
}

@article{wangInvestigationsWaterOxide2021,
    abstract = {Water/oxide interfaces are ubiquitous on earth and show significant influence on many chemical processes. For example, understanding water and solute adsorption as well as catalytic water splitting can help build better fuel cells and solar cells to overcome our looming energy crisis; the interaction between biomolecules and water/oxide interfaces is one hypothesis to explain the origin of life. However, knowledge in this area is still limited due to the difficulty of studying water/solid interfaces. As a result, research using increasingly sophisticated experimental techniques and computational simulations has been carried out in recent years. Although it is difficult for experimental techniques to provide detailed microscopic structural information, molecular dynamics (MD) simulations have satisfactory performance. In this review, we discuss classical and ab initio MD simulations of water/oxide interfaces. Generally, we are interested in the following questions: How do solid surfaces perturb interfacial water structure? How do interfacial water molecules and adsorbed solutes affect solid surfaces and how do interfacial environments affect solvent and solute behavior? Finally, we discuss progress in the application of neural network potential based MD simulations, which offer a promising future because this approach has already enabled ab initio level accuracy for very large systems and long trajectories. This article is categorized under: Theoretical and Physical Chemistry {$>$} Spectroscopy Molecular and Statistical Mechanics {$>$} Molecular Interactions Structure and Mechanism {$>$} Molecular Structures},
    annotation = {WOS:000657137500001},
    author = {Wang, Ruiyu and Klein, Michael L. and Carnevale, Vincenzo and Borguet, Eric},
    date = {2021},
    doi = {10.1002/wcms.1537},
    issn = {1759-0876},
    journaltitle = {Wiley Interdisciplinary Reviews-Computational Molecular Science},
    langid = {english},
    location = {{Hoboken}},
    pages = {e1537},
    publisher = {{Wiley}},
    shortjournal = {Wiley Interdiscip. Rev.-Comput. Mol. Sci.},
    title = {Investigations of Water/Oxide Interfaces by Molecular Dynamics Simulations},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06}
}

@article{wangPhysicsGuidedDeepLearning2021,
    abstract = {Modeling complex physical dynamics is a fundamental task in science and engineering. Traditional physics-based models are interpretable but rely on rigid assumptions. And the direct numerical approximation is usually computationally intensive, requiring significant computational resources and expertise. While deep learning (DL) provides novel alternatives for efficiently recognizing complex patterns and emulating nonlinear dynamics, it does not necessarily obey the governing laws of physical systems, nor do they generalize well across different systems. Thus, the study of physics-guided DL emerged and has gained great progress. It aims to take the best from both physics-based modeling and state-of-the-art DL models to better solve scientific problems. In this paper, we provide a structured overview of existing methodologies of integrating prior physical knowledge or physics-based modeling into DL and discuss the emerging opportunities.},
    archiveprefix = {arXiv},
    author = {Wang, Rui},
    date = {2021-08-01},
    eprint = {2107.01272},
    eprinttype = {arxiv},
    langid = {english},
    primaryclass = {cs},
    shorttitle = {Physics-{{Guided Deep Learning}} for {{Dynamical Systems}}},
    title = {Physics-{{Guided Deep Learning}} for {{Dynamical Systems}}: {{A}} Survey},
    url = {http://arxiv.org/abs/2107.01272},
    urldate = {2021-08-11}
}

@article{Weinan2020,
    abstract = {Machine learning is poised as a very powerful tool that can drastically improve our ability to carry out scientific research. However, many issues need to be addressed before this becomes a reality. This article focuses on one particular issue of broad interest: How can we integrate machine learning with physics-based modeling to develop new interpretable and truly reliable physical models? After introducing the general guidelines, we discuss the two most important issues for developing machine learning-based physical models: Imposing physical constraints and obtaining optimal datasets. We also provide a simple and intuitive explanation for the fundamental reasons behind the success of modern machine learning, as well as an introduction to the concurrent machine learning framework needed for integrating machine learning with physics-based modeling. Molecular dynamics and moment closure of kinetic equations are used as examples to illustrate the main issues discussed. We end with a general discussion on where this integration will lead us to, and where the new frontier will be after machine learning is successfully integrated into scientific modeling.},
    author = {Weinan, E and Han, Jiequn and Linfeng, Zhang},
    date = {2020-06},
    title = {Integrating Machine Learning with Physics-Based Modeling},
    url = {https://arxiv.org/abs/2006.02619 http://arxiv.org/abs/2006.02619 https://deepai.org/publication/integrating-machine-learning-with-physics-based-modeling}
}

@article{weinanMachineLearningComputational2020,
    abstract = {Neural network-based machine learning is capable of approximating functions in very high dimension with unprecedented efficiency and accuracy. This has opened up many exciting new possibilities, not just in traditional areas of artificial intelligence, but also in scientific computing and computational science. At the same time, machine learning has also acquired the reputation of being a set of "black box" type of tricks, without fundamental principles. This has been a real obstacle for making further progress in machine learning. In this article, we try to address the following two very important questions: (1) How machine learning has already impacted and will further impact computational mathematics, scientific computing and computational science? (2) How computational mathematics, particularly numerical analysis, can impact machine learning? We describe some of the most important progress that has been made on these issues. Our hope is to put things into a perspective that will help to integrate machine learning with computational mathematics.},
    annotation = {WOS:000592624200002},
    author = {Weinan, E.},
    date = {2020-11},
    doi = {10.4208/cicp.OA-2020-0185},
    issn = {1815-2406},
    journaltitle = {Communications in Computational Physics},
    langid = {english},
    location = {{Wanchai}},
    number = {5},
    pages = {1639--1670},
    publisher = {{Global Science Press}},
    shortjournal = {Commun. Comput. Phys.},
    title = {Machine {{Learning}} and {{Computational Mathematics}}},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/3},
    urldate = {2021-08-06},
    volume = {28}
}

@article{westermayrMachineLearningElectronically2020,
    abstract = {Electronically excited states of molecules are at the heart of photochemistry, photophysics, as well as photobiology and also play a role in material science. Their theoretical description requires highly accurate quantum chemical calculations, which are computationally expensive. In this review, we focus on not only how machine learning is employed to speed up such excited-state simulations but also how this branch of artificial intelligence can be used to advance this exciting research field in all its aspects. Discussed applications of machine learning for excited states include excited-state dynamics simulations, static calculations of absorption spectra, as well as many others. In order to put these studies into context, we discuss the promises and pitfalls of the involved machine learning techniques. Since the latter are mostly based on quantum chemistry calculations, we also provide a short introduction into excited-state electronic structure methods and approaches for nonadiabatic dynamics simulations and describe tricks and problems when using them in machine learning for excited states of molecules.},
    author = {Westermayr, Julia and Marquetand, Philipp},
    date = {2020},
    doi = {10.1021/acs.chemrev.0c00749},
    journaltitle = {Chemical Reviews},
    publisher = {{ACS Publications}},
    title = {Machine Learning for Electronically Excited States of Molecules},
    url = {https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.0c00749}
}

@article{Willard,
    abstract = {There is a growing consensus that solutions to complex science and engineering problems require novel methodologies that are able to integrate traditional physics-based modeling approaches with state-of-the-art machine learning (ML) techniques. This paper provides a structured overview of such techniques. Applicationcentric objective areas for which these approaches have been applied are summarized, and then classes of methodologies used to construct physics-guided ML models and hybrid physics-ML frameworks are described. We then provide a taxonomy of these existing techniques, which uncovers knowledge gaps and potential crossovers of methods between disciplines that can serve as ideas for future research.},
    author = {Willard, J and Jia, X and Xu, S and Steinbach, M and Kumar, V},
    date = {2021},
    journaltitle = {arxiv.org},
    title = {Integrating Physics-Based Modeling with Machine Learning: {{A}} Survey},
    url = {https://arxiv.org/abs/2003.04919}
}

@thesis{xieDeepLearningMethods2020,
    abstract = {The trend of open material data and automation in the past decade offers a unique opportunity for data-driven design of novel materials for various applications as well as fundamental scientific understanding, but it also poses a challenge for conventional machine learning approaches based on structure features. In this thesis, I develop a class of deep learning methods that solve various types of learning problems for solid materials, and demonstrate its application to both accelerate material design and understand scientific knowledge. First, I present a neural network architecture to learn the representations of an arbitrary solid material, which encodes several fundamental symmetries for solid materials as inductive biases. Then, I extend the approach to explore four different learning problems: 1) supervised learning to predict material properties from structures; 2) visualization to understand structure-property relations; 3) unsupervised learning to understand atomic scale dynamics from time series trajectories; 4) active learning to explore an unknown material space. In each learning problem, I demonstrate the performance of the approach compared with previous approaches, and apply it to solve several realistic materials design problems and extract scientific insights from data.},
    author = {Xie, Tian},
    date = {2020},
    institution = {{Massachusetts Institute of Technology}},
    title = {Deep Learning Methods for the Design and Understanding of Solid Materials},
    type = {PhD Thesis}
}

@article{xuPerspectiveComputationalReaction2021,
    abstract = {Heterogeneous catalysis plays a significant role in the modern chemical industry. Towards the rational design of novel catalysts, understanding reactions over surfaces is the most essential aspect. Typical industrial catalytic processes such as syngas conversion and methane utilisation can generate a large reaction network comprising thousands of intermediates and reaction pairs. This complexity not only arises from the permutation of transformations between species but also from the extra reaction channels offered by distinct surface sites. Despite the success in investigating surface reactions at the atomic scale, the huge computational expense of ab initio methods hinders the exploration of such complicated reaction networks. With the proliferation of catalysis studies, machine learning as an emerging tool can take advantage of the accumulated reaction data to emulate the output of ab initio methods towards swift reaction prediction. Here, we briefly summarise the conventional workflow of reaction prediction, including reaction network generation, ab initio thermodynamics and microkinetic modelling. An overview of the frequently used regression models in machine learning is presented. As a promising alternative to full ab initio calculations, machine learning interatomic potentials are highlighted. Furthermore, we survey applications assisted by these methods for accelerating reaction prediction, exploring reaction networks, and computational catalyst design. Finally, we envisage future directions in computationally investigating reactions and implementing machine learning algorithms in heterogeneous catalysis.},
    annotation = {WOS:000648898600001},
    author = {Xu, Jiayan and Cao, Xiao-Ming and Hu, P.},
    date = {2021-05-21},
    doi = {10.1039/d1cp01349a},
    issn = {1463-9076},
    journaltitle = {Physical Chemistry Chemical Physics},
    langid = {english},
    location = {{Cambridge}},
    number = {19},
    pages = {11155--11179},
    publisher = {{Royal Soc Chemistry}},
    shortjournal = {Phys. Chem. Chem. Phys.},
    title = {Perspective on Computational Reaction Prediction Using Machine Learning Methods in Heterogeneous Catalysis},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/1},
    urldate = {2021-08-06},
    volume = {23}
}

@article{yangRecentProgressMultiscale2021,
    abstract = {Computational electrochemistry, an important branch of electrochemistry, has shown its advantages in studying electrode/electrolyte interfaces, such as the structures of electric double layers. However, modeling electrochemical systems is still a challenge, especially in interface electrochemistry, because not only solvation effects and ion distribution in electrolyte solutions should be considered, but also the treatment of the electrode potential and the response of electrolytes to applied potentials. Here, we review the latest development in the field of computational electrochemistry. We first introduce various energy models used in simulating electrolytes and electrodes at multiple scales. Then, to better explain and compare between different methods, we discuss the calculation methods of solution electrochemistry and interface electrochemistry in separate. At last, we introduce the methods to electrify the interfaces in various multiscale models. This review aims to help understand various levels of methods in simulations of different scenarios in electrochemistry, and summarizes a set of schemes covering multiple scales. This article is categorized under: Electronic Structure Theory ¿ Combined QM/MM Methods Molecular and Statistical Mechanics ¿ Molecular Dynamics and Monte-Carlo Methods Electronic Structure Theory ¿ Density Functional Theory.},
    author = {Yang, Xiao‐Hui and Zhuang, Yong‐Bin and Zhu, Jia‐Xin and Le, Jia‐Bo and Cheng, Jun},
    date = {2021-06},
    doi = {10.1002/wcms.1559},
    journaltitle = {WIREs Computational Molecular Science},
    publisher = {{Wiley}},
    title = {Recent Progress on Multiscale Modeling of Electrochemistry}
}

@article{yeMachineLearningCoarseGrained2021,
    author = {Ye, Huilin and Xian, Weikang and Li, Ying},
    date = {2021},
    doi = {10.1021/acsomega.0c05321},
    journaltitle = {ACS omega},
    number = {3},
    pages = {1758--1772},
    publisher = {{ACS Publications}},
    shorttitle = {Machine {{Learning}} of {{Coarse}}-{{Grained Models}} for {{Organic Molecules}} and {{Polymers}}},
    title = {Machine {{Learning}} of {{Coarse}}-{{Grained Models}} for {{Organic Molecules}} and {{Polymers}}: {{Progress}}, {{Opportunities}}, and {{Challenges}}},
    volume = {6}
}

@article{Zhang2020c,
    abstract = {In recent years, machine learning has emerged as a promising tool for dealing with the difficulty of representing high dimensional functions. This gives us an unprecedented opportunity to revisit theoretical foundations of various scientific fields, develop new schemes, improve existing methodologies, and solve problems that were too complicated for conventional approaches to address. In this dissertation, we identify a list of such problems in the context of multiscale molecular modeling and propose machine learning based strategies to boost simulations with ab initio accuracy to much larger scales than conventional approaches. We consider two representative challenges: 1) how to go from many-electron-ion to atomistic systems, for which the key has been a general and efficient representation of the potential energy surface generated by electronic structure models; 2) how to go from atomistic to coarse-grained systems, for which one is interested in the free energy of the coarse-grained variables as well as the associated dynamical behavior. Our strategies follow two seemingly obvious but non-trivial principles: 1) machine learning based models should respect important physical constraints like symmetry; 2) to build truly reliable models, efficient algorithms are needed to construct a minimal but truly representative training data set. We use these principles to construct the Deep Potential model for the potential energy surface, the Deep Potential Molecular dynamics (DeePMD) which is a new paradigm for performing ab initio molecular dynamics, a concurrent learning scheme (DP-GEN) for generating the data set on the fly, algorithms for constructing the Wannier centers (Deep Wanner) and for efficiently exploring the free energy landscape (Reinforced Dynamics), as well as a machine learning-based coarse grained molecular dynamics model (DeePCG), etc.Applications of these models and algorithms are presented for problems in chemistry, biology, and materials science. Finally, we present our efforts on developing related open-source software packages, which have now been widely used worldwide by experts and practitioners in the molecular simulation community.},
    author = {Zhang, L},
    date = {2020},
    title = {Machine Learning for Multi-Scale Molecular Modeling: Theories, Algorithms, and Applications},
    url = {https://search.proquest.com/openview/58ad7a1fdcc88005de25b81cd4cdc5d8/1?pq-origsite=gscholar&cbl=51922&diss=y}
}

@article{zhangGlobalOptimizationChemical2021,
    abstract = {Chemical clusters are relevant to many applications in catalysis, separations, materials, and energy sciences. Experimentally, the structure of clusters is difficult to determine, but it is very important in understanding their chemistry and properties. Computational methods can be used to examine cluster structure, however finding the most stable structure is not simple, particularly as the cluster size increases. Global optimization techniques have long been used to tackle the problem of the most stable structure, but such approaches would have to look for a global minimum, while sampling local minima over the whole potential energy surface as well. In this review, the state-of-the-art theory of global optimization theory is summarized. First, the definition, significance, relation to experiments, and a brief history of global optimization is presented. We then discuss, in more detail, three versatile global optimization methods: the basin hopping, the artificial bee colony algorithm, and the genetic algorithm. We close with some representative application examples of global optimization of clusters since 2016 and the challenges, open questions and opportunities in this field.},
    annotation = {WOS:000591191600001},
    author = {Zhang, Jun and Glezakou, Vassiliki-Alexandra},
    date = {2021-04-05},
    doi = {10.1002/qua.26553},
    issn = {0020-7608},
    journaltitle = {International Journal of Quantum Chemistry},
    langid = {english},
    location = {{Hoboken}},
    number = {7},
    pages = {e26553},
    publisher = {{Wiley}},
    shortjournal = {Int. J. Quantum Chem.},
    shorttitle = {Global Optimization of Chemical Cluster Structures},
    title = {Global Optimization of Chemical Cluster Structures: {{Methods}}, Applications, and Challenges},
    url = {https://www.webofscience.com/wos/alldb/summary/44a3404b-9775-4cfb-8e8f-3f1fab40830f-035e7f8d/date-descending/3},
    urldate = {2021-08-06},
    volume = {121}
}

@thesis{zhangNoncontactUltrasound2019,
    author = {Zhang, Xiang},
    date = {2019},
    institution = {{Massachusetts Institute of Technology}},
    title = {Non-Contact Ultrasound},
    type = {PhD Thesis}
}